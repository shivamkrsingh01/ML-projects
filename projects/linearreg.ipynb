{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      ":Number of Instances: 442\n",
      "\n",
      ":Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      ":Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      ":Attribute Information:\n",
      "    - age     age in years\n",
      "    - sex\n",
      "    - bmi     body mass index\n",
      "    - bp      average blood pressure\n",
      "    - s1      tc, total serum cholesterol\n",
      "    - s2      ldl, low-density lipoproteins\n",
      "    - s3      hdl, high-density lipoproteins\n",
      "    - s4      tch, total cholesterol / HDL\n",
      "    - s5      ltg, possibly log of serum triglycerides level\n",
      "    - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = load_diabetes()\n",
    "print(dt['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:  ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "First five:  [151.  75. 141. 206. 135.]\n"
     ]
    }
   ],
   "source": [
    "x = dt.data\n",
    "y = dt.target\n",
    "print('features: ', dt.feature_names)\n",
    "print('First five: ', y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "target_scaler = StandardScaler()\n",
    "\n",
    "x = feature_scaler.fit_transform(x)\n",
    "\n",
    "y = y.reshape(-1, 1)\n",
    "y = target_scaler.fit_transform(y)\n",
    "y = y.ravel()\n",
    "\n",
    "x, x_test , y, y_test = train_test_split(x, y ,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = x.shape\n",
    "w = np.zeros(n)\n",
    "b =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b):\n",
    "    return np.dot(x, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_cost(x, y, w, b):\n",
    "    m = len(y)\n",
    "    y_pred = predict(x , w , b)\n",
    "    cost = (1 / (2 * m)) * np.sum((y_pred - y) ** 2)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_grad(X, y, w, b):\n",
    "\n",
    "    m = len(y)\n",
    "    y_pred = predict(X, w, b)\n",
    "    error = y_pred - y\n",
    "\n",
    "    dw = (1 / m) * np.dot(X.T, error)\n",
    "    db = (1 / m) * np.sum(error)\n",
    "\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_para(w, b, dw, db, learning_rate):\n",
    "\n",
    "    w = w - learning_rate * dw\n",
    "    b = b - learning_rate * db\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Cost = 0.5126\n",
      "Iteration 1000: Cost = 0.2580\n",
      "Iteration 2000: Cost = 0.2465\n",
      "Iteration 3000: Cost = 0.2448\n",
      "Iteration 4000: Cost = 0.2444\n",
      "Iteration 5000: Cost = 0.2443\n",
      "Iteration 6000: Cost = 0.2442\n",
      "Iteration 7000: Cost = 0.2442\n",
      "Iteration 8000: Cost = 0.2442\n",
      "Iteration 9000: Cost = 0.2441\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros(n)\n",
    "b = 0\n",
    "\n",
    "learning_rate = .001\n",
    "num_iterations = 10000\n",
    "cost_history = []\n",
    "\n",
    "parameters = {}\n",
    "\n",
    "for i in range(num_iterations):\n",
    "\n",
    "    y_pred = predict(x, w, b)\n",
    "    cost = comp_cost(x, y, w, b)\n",
    "    dw, db = comp_grad(x, y, w, b)\n",
    "    w, b = update_para(w, b, dw, db, learning_rate)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "      cost_history.append(cost)\n",
    "      print(f'Iteration {i}: Cost = {cost:.4f}')\n",
    "\n",
    "      parameters = {'weights': w.tolist(), 'bias': b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Cost: 0.2441\n",
      "Mean Squared Error: 0.4881\n",
      "Final Weights: [ 0.0259686  -0.14838151  0.34424672  0.21164906 -0.08594714 -0.06166533\n",
      " -0.12128665  0.09817543  0.26812243  0.0340318 ]\n",
      "Final Bias: -0.010765538732703505\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(x , w, b)\n",
    "final_cost = comp_cost(x, y, w, b)\n",
    "mse = 2 * final_cost\n",
    "\n",
    "print(f'Final Cost: {final_cost:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')\n",
    "print('Final Weights:', w)\n",
    "print('Final Bias:', b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual Analysis : 0.5570976012136875\n",
      "Mean Absolute Error (MAE): 0.5571\n",
      "Mean Squared Error (MSE): 0.4865\n",
      "Root Mean Squared Error (RMSE): 0.6975\n",
      "R-squared: 0.4554\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = predict(x_test, w, b)\n",
    "\n",
    "print(f\"Residual Analysis : {(np.abs(y_test - y_pred_test)).mean()}\")\n",
    "\n",
    "mae = np.abs(y_test - y_pred_test).mean()\n",
    "mse = ((y_test - y_pred_test)**2).mean()\n",
    "rmse = np.sqrt(((y_test - y_pred_test)**2).sum()/len(y_test))\n",
    "\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "\n",
    "SS_res = np.sum((y_test - y_pred_test)**2)        \n",
    "SS_tot = np.sum((y_test - np.mean(y_test))**2)    \n",
    "\n",
    "r2_ = 1 - (SS_res / SS_tot)\n",
    "\n",
    "print(f\"R-squared: {r2_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.4869\n",
      "R-squared: 0.4551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model = SGDRegressor(\n",
    "    loss='squared_error',\n",
    "    alpha=0.0,\n",
    "    learning_rate='constant', \n",
    "    eta0=0.001,                 \n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    "  )\n",
    "\n",
    "\n",
    "model.fit(x, y)  \n",
    "\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "r2 = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R-squared: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scratch model weights :  [ 0.02570603 -0.14462578  0.33891888  0.20913889 -0.0605443  -0.08162086\n",
      " -0.13815758  0.08992119  0.25121163  0.04993703]\n",
      "sklearn model weights :  [ 0.0259686  -0.14838151  0.34424672  0.21164906 -0.08594714 -0.06166533\n",
      " -0.12128665  0.09817543  0.26812243  0.0340318 ]\n"
     ]
    }
   ],
   "source": [
    "print('scratch model weights : ' , model.coef_)\n",
    "print('sklearn model weights : ' , w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
